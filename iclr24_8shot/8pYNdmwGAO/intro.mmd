## 1 Introduction

_Can we predict important properties of a protein by directly observing only the effect of a few mutations on such properties?_ This basic biological question (Wells, 1990; Fowler & Fields, 2014) has recently engaged the machine learning community due to the current availability of benchmark data (Rao et al., 2019; Dallago et al., 2021; Xu et al., 2022). Proteins are sequences of amino-acids (residues), which are the cornerstone of life and influence a number of metabolic processes, including diseases (Pauling et al., 1951; Ideker & Sharan, 2008). For this reason, protein engineering stands at the forefront of modern biotechnology, offering a remarkable toolkit to manipulate and optimise existing proteins for a wide range of applications, from drug development to personalised therapy (Ulmer, 1983; Carter, 2011; Alley et al., 2019).

One fundamental process in protein engineering progressively mutates an initial protein, called the _wild-type_, to study the effect on the protein's properties (Siezen et al., 1991). These mutations form a family of _homologous proteins_ as in Figure 1. This process is appealing due to its cheaper cost compared to other methods and reduced time and risk (Wang et al., 2012; Engqvist & Rabe, 2019).

Yet, the way mutations affect the protein's properties is not completely understood (Bryant et al., 2021; Sarkisyan et al., 2016; Wu et al., 2016), as it depends on a number of chemical reactions and bonds among residues. For this reason, machine learning offers a viable alternative to model complex interactions among residues. Initial approaches employed _feature engineering_ to capture protein's evolution (Saravanan & Gautham, 2015; Feng & Zhang, 2000); yet, a manual approach is expensive and does not offer enough versatility. Advances in NLP and CV inspired the design of deep _protein sequence encoders_(Hochreiter & Schmidhuber, 1997; Yu et al., 2017; Vaswani et al., 2017) and general purpose Protein Language Models (PLMs) that are pre-trained on large scale datasets of sequences. Notable PLMs include ProtBert (Brandes et al., 2022), AlphaFold (Jumper et al., 2021), TAPE Transformer (Rao et al., 2019) and ESM (Rives et al., 2021). These models mainly rely on Multiple Sequence Alignments (MSAs) (Meier et al., 2021) to search on large databases of protein evolution. Nevertheless, this search process is insensitive to subtle yet crucial mutations and introduces additional computational burdens (Pearson, 2013; Chatzou et al., 2016).

To overcome the limitations of previous models, we propose EvolMPNN, Evolution-aware Message Passing Neural Network, to predict the mutational effect on homologous proteins. Our fundamental assumption is that there are inherent correlations between protein properties and the sequence differences among them, as shown in Figure 1-(b). EvolMPNN integrates both protein sequence and evolutionary information by identifying where and which mutations occur on the target protein sequence, compared with known protein sequences and predicts the mutational effect on the target protein property. To avoid the costly _quadratic_ pairwise comparison among proteins, we devise a theoretically grounded (see Section 4.6) _linear_ sampling strategy to compute differences only among the proteins and a fixed number of anchor proteins (Section 4.2). We additionally introduce two extensions of our model, EvolGNN and EvolFormer, to include available data on the relation among proteins (Section 4.5). The theoretical computation complexity of proposed methods are provided to guarantee their efficiency and practicality. We apply the proposed methods to three benchmark homologous protein property prediction datasets with nine splits. Empirical evaluation results (Section 5.1) show up to \(6.7\%\) Spearman's \(\rho\) correlation improvement over the best performing baseline models, reducing the inference time by \(36\times\) compared with pre-trained PLMs.


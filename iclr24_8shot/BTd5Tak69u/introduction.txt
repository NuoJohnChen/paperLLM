When humans observe their surrounding world, numerous objects are regarded as features to understand the world (Johnson, 2010). Compared with perceiving the whole scene directly, knowledge can be acquired from the surrounding world more efficiently through compositional perception (Fodor & Pylyshyn, 1988). Therefore, to make the artificial intelligence systems learn the knowledge of the world as efficiently as human beings, it is crucial to perceive the scene in a compositional way (Lake et al., 2017). Object-Centric Learning (OCL) is a compositional scene perception method that focuses on separately learning the representations of individual objects in a scene. Recently, object-centric representation learning has attracted much attention and multiple outstanding works have been summarized (Yuan et al., 2022a). For example, the methods, such as AIR (Eslami et al., 2016), GMIOO (Yuan et al., 2019), SPACE (Lin et al., 2019), Slot Attention (Locatello et al., 2020), GENESIS-v2 (Engelcke et al., 2021), SLATE (Singh et al., 2022a), DINOSAUR (Seitzer et al., 2023) etc., work well on the static scene. The methods, such as SQAIR (Kosiorek et al., 2018), SCALOR (Jiang et al., 2019), G-SWM (Lin et al., 2020), etc., learn better compositional scene representations by modeling the motions and relationships of objects in the scene. The methods, such as SIMONe (Kabra et al., 2021), MulMON (Li et al., 2020), OCLOC (Yuan et al., 2022b), focus on observing the scene from multiple viewpoints. The methods, such as SAVi (Kipf et al., 2022), SAVi++ (Elsayed et al., 2022), STEVE (Singh et al., 2022b), apply object-centric learning to videos. Despite the proficiency of the above methods in extracting object-centric representations, they still have some limitations in processing complex scenes. On the one hand, methods such as Slot Attention, OCLOC, and SIMONe cannot segment the object in the complex scenes well. On the other hand, methods such as DINOSAUR and STEVE face difficulties constructing individual object images through their corresponding representations to obtain the gratifying performance of decomposition on complex scenes. A fundamental ability of the human brain is invariant object recognition, which involves the rapid and precise identification of objects based on their relatively consistent (invariant) features despite variances in size, rotation, and position (Karimi-Rouzbahani et al., 2017). What’s more, humans have the ability to distinguish between relatively consistent (invariant) features and view-specific (non-invariant) features of an object from different viewpoints (Turnbull et al., 1997). Inspired by these human cognitive capabilities, we propose learning the viewpoint-independent representation of objects in 3D scenes to identify consistent objects in the image viewed from multiple perspectives. In this paper, we propose a novel object-centric learning method, called Learning Object-centric Representation from Multi-viewpoint (LORM), for learning object-centric representation from multiple-viewpoint scenes in an unsupervised manner. Specifically, we assume that a compositional scene representation consists of viewpoint and multiple object representations. Viewpoint representations correspond to the scene’s global view-specific elements (such as camera position). Object representations indicate objects’ viewpoint-independent attributes (such as appearance, shape, scale and position) in 3D scenes. The former is the output of a viewpoint encoder, and the latter is obtained by a slot attention encoder with the image feature and viewpoint representation as inputs. Moreover, we propose a mixture patch decoder to reconstruct the individual object image observed from a specific viewpoint by the corresponding object and viewpoint representations. It can not only decompose complex scenes but also reconstruct the individual object image. The experiment section uses three complex simulations (i.e., CLEVR-A (Johnson et al., 2017), SHOP (Nazarczuk & Mikolajczyk, 2020) and GSO (Greff et al., 2022)) multi-view scene data to evaluate the proposed method. Two representative multi-viewpoint-based methods, OCLOC (Yuan et al., 2022b) and SIMONe (Kabra et al., 2021), and two with outstanding performance in complex scenes, DINOSAUR (Seitzer et al., 2023) and STEVE (Singh et al., 2022b), are selected as comparison methods. The abundant experimental results show that the proposed method not only has outstanding performance of decomposition on complex scenes but also can reconstruct the individual object image well. In summary, the contributions of this work are as follows: 1) We propose a novel object-centric representation learning method that learns object representation from multi-view scenes without supervision. 2) We propose an object-centric encoder, consisting of a viewpoint encoder and slot attention encoder, to disentangle the scene representation into viewpoint and object representation. 3) We propose a mixture patch decoder to reconstruct an object image with the individual object and corresponding viewpoint representations as inputs. 4) LORM is the first object-centric learning method that can decompose complex scenes and reconstruct the image of individual objects simultaneously.
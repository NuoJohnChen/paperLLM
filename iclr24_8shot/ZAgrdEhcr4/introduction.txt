Optimization serves as a fundamental component in numerous real-world applications and machine learning algorithms. For instance, it plays an essential role in optimizing vehicle routes for costefficiency in logistics (Thanh et al., 2023), forms the core of hyperparameter tuning in AutoML (Zhang et al., 2023), defines and minimizes the multiple loss functions in multitask learning (Lin et al., 2019), etc. The optimization problems in these applications may be challenging due to their non-convex, multiobjective, evaluation-expensive, and/or large-scale nature. Addressing such challenges demands the use of well-designed optimizers, with evolutionary algorithms (EAs) standing out as promising problem-solving tools (Liu, 2022). Nevertheless, EAs can be computationally demanding, which limits their adaptability to lightweight optimization requirements (Coello Coello et al., 2020). In recent years, there has been a growing emphasis on conducting computations closer to data sources, such as onboard or alongside a connected camera in a self-driving car, to enable real-time optimization services (Gulotta, 2023). This shift has led to a transition of computing from the centralized cloud to the edge devices, where computing resources are severely limited. However, many existing EAs were developed without considering these resource limitations. In the quest for lightweight optimization, EAs must enhance efficiency to address the growing complexity of challenges (Del Ser et al., 2019), notably those related to large model and big data optimization that are often computationally demanding, particularly in terms of function evaluations (Chugh et al., 2019). Building on the observations outlined above, this study aims to enhance the efficiency of EAs for solving large-scale multi-objective optimization problems (LMOPs). In the literature, extensive efforts have been dedicated to improve EAs for solving LMOPs, which can be broadly classified into three main categories: Decomposition of Search Space: This approach employs a divide-and-conquer mechanism, where decision variables are grouped or clustered by the developed variable decomposition methods (Zhao et al., 2022), including linear, random, and differential based methods (Ou et al., 2022). Optimization is then carried out collaboratively on each of these groups (subspaces), simplifying the problem-solving process (Zhong et al., 2022). However, it typically relies on rich domain exper- tise for problem decomposition which may not be available. Incorrect grouping of variables may mislead evolutionary search and slow down population convergence (Duan et al., 2023). Analyzing the importance (or contribution) of variables and their interrelationships before grouping requires a substantial number of function evaluations (Liu et al., 2022). Dimension Reduction of Search Space: This method transforms the original LMOP into smallerscale problems using existing dimensionality reduction technique, such as random embedding (Qian & Yu, 2017), unsupervised neural networks (Tian et al., 2020), problem transformation (Zille et al., 2016), and principal component analysis (Liu et al., 2020). This conversion allows optimization to take place in a simplified representation space, leading to a substantial reduction in the volume of the high-dimensional search space. Nevertheless, it does not guarantee the preservation of the original global or near-global optimum when operating within the compressed search space, and thus it may potentially miss certain optimal regions, making populations susceptible to local optima entrapment. The dimensionality reduction process often overlooks constraints related to computational resources. Design of Novel Search Strategy: In contrast to the preceding methods that alleviate problem complexity before optimization, this category of algorithms tackles LMOPs directly, taking all decision variables into account. It achieves this by designing new, powerful evolutionary search strategies for offspring reproduction, such as competitive learning-based search (Liu et al., 2021), bidirectionalguided adaptive search (He et al., 2020a), adversarial learning-aided search (Wang et al., 2021b), and fuzzy-controlled search (Yang et al., 2021). Without proper guidance towards the correct search direction, thereâ€™s a likelihood of venturing into the misleading areas during optimization, resulting in a wasteful consumption of computing resources (Omidvar et al., 2021). These novel search strategies still fall considerably short of meeting the demands for lightweight optimization. Despite these efforts, their search capabilities often fall short of effectively handling the exponentially expanded search space within the constraints of acceptable computational resources. In pursuit of accelerated evolutionary optimization, researchers have investigated online innovization progress operators aimed at guiding offspring towards learned promising directions (Deb & Srinivasan, 2006). These operators involve training machine learning models online to get performance improvement representations of solutions (Gaur & Deb, 2017). This process encompasses three primary steps: gathering solutions from previous generations, training the model to identify patterns, and utilizing it to rectify newly generated offspring (Mittal et al., 2020). However, existing innovization operators are only developed for small-scale optimization. In addition, the online training of deep models introduces computational overhead, particularly in the context of large-scale optimization, and the resulting acceleration in convergence still falls short of expectations. In response, to expedite the optimization of LMOPs, this work introduces a deep accelerated evolutionary search strategy driven by an inexpensive large model, which is stacked repeatedly by multiple lightweight models. This study presents three main contributions: 1) Development of a lightweight model capable of learning both compressed and performance improvement representations of solutions. 2) Analysis of the varying impacts of evolutionary search in the learned representation space. 3) Design of a large model for acquiring deep improvement representations (DIR) of solutions, aimed at enabling efficent optimization of LMOPs. The relevant background, technical details, and specific experimental design and verification are respectively elaborated in sections 2, 3, and 4 below.